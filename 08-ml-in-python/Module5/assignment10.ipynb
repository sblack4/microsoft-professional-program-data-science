{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.io.wavfile as wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Good Luck!\n",
    "\n",
    "#\n",
    "# INFO:\n",
    "# Samples = Observations. Each audio file will is a single sample\n",
    "#           in our dataset.\n",
    "#\n",
    "# Audio Samples = https://en.wikipedia.org/wiki/Sampling_(signal_processing)\n",
    "# Each .wav file is actually just a bunch of numeric samples, \"sampled\"\n",
    "# from the analog signal. Sampling is a type of discretization. When we\n",
    "# mention 'samples', we mean observations. When we mention 'audio samples',\n",
    "# we mean the actually \"features\" of the audio file.\n",
    "#\n",
    "#\n",
    "# The goal of this lab is to use multi-target, linear regression to generate\n",
    "# by extrapolation, the missing portion of the test audio file.\n",
    "#\n",
    "# Each one audio_sample features will be the output of an equation,\n",
    "# which is a function of the provided portion of the audio_samples:\n",
    "#\n",
    "#    missing_samples = f(provided_samples)\n",
    "#\n",
    "# You can experiment with how much of the audio you want to chop off\n",
    "# and have the computer generate using the Provided_Portion parameter.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# TODO: Play with this. This is how much of the audio file will\n",
    "# be provided, in percent. The remaining percent of the file will\n",
    "# be generated via linear extrapolation.\n",
    "Provided_Portion = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "# TODO: Just for a second, convert zero into a DataFrame. When you do\n",
    "# so, set the dtype to np.int16, since the input audio files are 16\n",
    "# bits per sample. If you don't know how to do this, read up on the docs\n",
    "# here:\n",
    "# http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n",
    "#\n",
    "# Since these audio clips are unfortunately not length-normalized,\n",
    "# we're going to have to just hard chop them to all be the same length.\n",
    "# Since Pandas would have inserted NANs at any spot to make zero a \n",
    "# perfectly rectangular [n_observed_samples, n_audio_samples] array,\n",
    "# do a dropna on the Y axis here. Then, convert one back into an\n",
    "# NDArray using .values\n",
    "#\n",
    "# .. your code here ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: It's important to know how (many audio_samples samples) long the\n",
    "# data is now. 'zero' is currently shaped [n_samples, n_audio_samples],\n",
    "# so get the n_audio_samples count and store it in a variable called\n",
    "# n_audio_samples\n",
    "#\n",
    "# .. your code here .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Create your linear regression model here and store it in a\n",
    "# variable called 'model'. Don't actually train or do anything else\n",
    "# with it yet:\n",
    "#\n",
    "# .. your code here .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# INFO: There are 50 takes of each clip. You want to pull out just one\n",
    "# of them, randomly, and that one will NOT be used in the training of\n",
    "# your model. In other words, the one file we'll be testing / scoring\n",
    "# on will be an unseen sample, independent to the rest of your\n",
    "# training set:\n",
    "from sklearn.utils.validation import check_random_state\n",
    "rng   = check_random_state(7)  # Leave this alone until you've submitted your lab\n",
    "random_idx = rng.randint(zero.shape[0])\n",
    "test  = zero[random_idx]\n",
    "train = np.delete(zero, [random_idx], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "# TODO: Print out the shape of train, and the shape of test\n",
    "# train will be shaped: [n_samples, n_audio_samples], where\n",
    "# n_audio_samples are the 'features' of the audio file\n",
    "# train will be shaped [n_audio_features], since it is a single\n",
    "# sample (audio file, e.g. observation).\n",
    "#\n",
    "# .. your code here .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# INFO: The test data will have two parts, X_test and y_test. X_test is\n",
    "# going to be the first portion of the test audio file, which we will\n",
    "# be providing the computer as input. y_test, the \"label\" if you will,\n",
    "# is going to be the remaining portion of the audio file. Like such, \n",
    "# the computer will use linear regression to derive the missing\n",
    "# portion of the sound file based off of the training data its received!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Save the original 'test' clip, the one you're about to delete\n",
    "# half of, so that you can compare it to the 'patched' clip once \n",
    "# you've generated it. HINT: you should have got the sample_rate\n",
    "# when you were loading up the .wav files:\n",
    "wavfile.write('Original Test Clip.wav', sample_rate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Prepare the TEST date by creating a slice called X_test. It\n",
    "# should have Provided_Portion * n_audio_samples audio sample features,\n",
    "# taken from your test audio file, currently stored in the variable\n",
    "# 'test'. In other words, grab the FIRST Provided_Portion *\n",
    "# n_audio_samples audio features from test and store it in X_test.\n",
    "#\n",
    "# .. your code here .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: If the first Provided_Portion * n_audio_samples features were\n",
    "# stored in X_test, then we need to also grab the *remaining* audio\n",
    "# features and store it in y_test. With the remaining features stored\n",
    "# in there, we will be able to R^2 \"score\" how well our algorithm did\n",
    "# in completing the sound file.\n",
    "#\n",
    "# .. your code here .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Duplicate the same process for X_train, y_train. The only\n",
    "# differences being: 1) Your will be getting your audio data from\n",
    "# 'train' instead of from 'test', 2) Remember the shape of train that\n",
    "# you printed out earlier? You want to do this slicing but for ALL\n",
    "# samples (observations). For each observation, you want to slice\n",
    "# the first Provided_Portion * n_audio_samples audio features into\n",
    "# X_train, and the remaining go into y_test. All of this should be\n",
    "# accomplishable using regular indexing in two lines of code.\n",
    "#\n",
    "# .. your code here .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "# TODO: SciKit-Learn gets mad if you don't supply your training\n",
    "# data in the form of a 2D arrays: [n_samples, n_features].\n",
    "#\n",
    "# So if you only have one SAMPLE, such as is our case with X_test, \n",
    "# and y_test, then by calling .reshape(1, -1), you can turn\n",
    "# [n_features] into [1, n_features].\n",
    "#\n",
    "# On the other hand, if you only have one FEATURE, which currently\n",
    "# doesn't apply, you can call .reshape(-1, 1) on your data to turn\n",
    "# [n_samples] into [n_samples, 1]:\n",
    "#\n",
    "# .. your code here .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Fit your model using your training data and label:\n",
    "#\n",
    "# .. your code here .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "# TODO: Use your model to predict the 'label' of X_test. Store the\n",
    "# resulting prediction in a variable called y_test_prediction\n",
    "#\n",
    "# .. your code here ..\n",
    "\n",
    "\n",
    "# INFO: SciKit-Learn will use float64 to generate your predictions\n",
    "# so let's take those values back to int16:\n",
    "y_test_prediction = y_test_prediction.astype(dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "# TODO: Score how well your prediction would do for some good laughs,\n",
    "# by passing in your test data and test label (y_test).\n",
    "#\n",
    "# .. your code here ..\n",
    "print \"Extrapolation R^2 Score: \", score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# First, take the first Provided_Portion portion of the test clip, the\n",
    "# part you fed into your linear regression model. Then, stitch that\n",
    "# together with the abomination the predictor model generated for you,\n",
    "# and then save the completed audio clip:\n",
    "completed_clip = np.hstack((X_test, y_test_prediction))\n",
    "wavfile.write('Extrapolated Clip.wav', sample_rate, completed_clip[0])\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# INFO: Congrats on making it to the end of this crazy lab =) !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
